import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from scipy.stats import norm

def load_data(file_path):
    # Load data, skip the first column (date) and use only the 'Adjusted Close' column (6th column)
    data = pd.read_csv(file_path, usecols=[5])
    return data

def preprocess_data(data):
    # Standardize data
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(data)
    return scaled_data, scaler

def build_model(input_shape):
    # Build an LSTM model
    model = Sequential([
        LSTM(50, input_shape=input_shape, return_sequences=True),
        LSTM(50),
        Dense(4)  # predict mean, volatility, skewness, kurtosis
    ])
    model.compile(optimizer='adam', loss='mse')
    return model

def train_model(model, X, y, epochs=50, batch_size=32):
    # Fit model
    model.fit(X, y, epochs=epochs, batch_size=batch_size)

def prepare_data(data):
    # Prepare data for training
    X = []
    y = []
    window_size = 10  # Window size for the LSTM
    for i in range(len(data) - window_size):
        X.append(data[i:(i + window_size), 0])
        y.append(data[i + window_size, 0])
    X = np.array(X)
    y = np.array(y)
    X = X.reshape(X.shape[0], X.shape[1], 1)  # Reshape for LSTM [samples, time steps, features]
    return X, y

def predict_properties(model, X):
    # Make predictions
    predictions = model.predict(X)
    return predictions  # mean, volatility, skewness, kurtosis

def cornish_fisher_expansion(mean, vol, skew, kurt, alpha=0.05):
    z = norm.ppf(alpha)
    z_adj = z + (z**2 - 1)*skew/6 + (z**3 - 3*z)*(kurt-3)/24 - (2*z**3 - 5*z)*(skew**2)/36
    VaR = mean + z_adj * vol
    ES = mean - vol * (norm.pdf(norm.ppf(alpha)) / alpha)
    return VaR, ES

def main(file_paths):
    results = {}

    for file_path in file_paths:
        # Load and preprocess data
        data = load_data(file_path)
        data, scaler = preprocess_data(data.values)

        # Prepare training data
        X, y = prepare_data(data)
        
        # Build and train model
        model = build_model((X.shape[1], 1))
        train_model(model, X, y)

        # Predict properties using the last available window of data
        last_window = X[-1:].reshape(1, X.shape[1], 1)
        predictions = predict_properties(model, last_window)
        mean, vol, skew, kurt = predictions.flatten()

        # Calculate VaR and ES using Cornish-Fisher
        VaR, ES = cornish_fisher_expansion(mean, vol, skew, kurt)
        results[file_path] = {'VaR': VaR, 'ES': ES}

    return results

if __name__ == '__main__':
    file_paths = ['SVARX.csv']  # Example file paths
    results = main(file_paths)
    print(results)
